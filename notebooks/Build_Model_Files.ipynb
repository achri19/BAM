{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "466e2a39",
      "metadata": {
        "id": "466e2a39"
      },
      "source": [
        "<font size=\"8\">Build an ANUGA Model (BAM) </font>\n",
        "\n",
        "<font size=\"3\">In this notebook, we will:\n",
        "\n",
        "- set model configuration parameters\n",
        "\n",
        "- download and preprocess elevation and landcover datasets\n",
        "\n",
        "    \n",
        "- Determine water body polygons\n",
        "\n",
        "\n",
        "- Build the Digital Elevation Model\n",
        "\n",
        "\n",
        "\n",
        "</font>\n",
        "\n",
        "<font size=\"3\">This could take some time, depending on model domain size and complexity of the water mask</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jNhRqEni40KR",
      "metadata": {
        "id": "jNhRqEni40KR"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, set the variable yes_colab = True.</font> <br>\n",
        "<font size=5 color='blue'> If you are running on your own computer, set the variable yes_colab = False </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gkLaKjYy4_Lv",
      "metadata": {
        "id": "gkLaKjYy4_Lv"
      },
      "outputs": [],
      "source": [
        "yes_colab = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rhp4yA4h2Njc",
      "metadata": {
        "id": "rhp4yA4h2Njc"
      },
      "source": [
        "<font size=6> Step #1a: Set working directory <br> </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JkG2pXof2YoC",
      "metadata": {
        "id": "JkG2pXof2YoC"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, when you run the next cell, a pop-up window will appear asking you to grant access to your Google Drive. You must approve or the notebook will not work. <font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "s_IgSq3RgKtN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_IgSq3RgKtN",
        "outputId": "a44b2ec8-7687-48d5-9797-acb90bc5fbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Your working directory is /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "your_path = Path(os.getcwd() + '/')\n",
        "if yes_colab:\n",
        "  where_to_mount = '/content/drive/'\n",
        "  from google.colab import drive\n",
        "  drive.mount(where_to_mount, force_remount=True)\n",
        "  mounted_drive = Path(where_to_mount) / 'MyDrive' \n",
        "  sys.path.append(str(mounted_drive / 'installations'))\n",
        "  path_ancillary = mounted_drive / 'ancillary'\n",
        "  Path(mounted_drive / 'installations').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "else:\n",
        "  mounted_drive = Path(os.path.abspath(os.path.join(your_path, os.pardir)))\n",
        "  path_ancillary = mounted_drive / 'BAM/ancillary'\n",
        "\n",
        "print('Your working directory is %s' %(mounted_drive))\n",
        "\n",
        "# path_code = mounted_drive / \"BAM/scripts\"\n",
        "# path_templates = mounted_drive / 'BAM/templates'\n",
        "# path_configs = mounted_drive / 'BAM/configs'\n",
        "# path_examples = mounted_drive / 'BAM/examples'\n",
        "# Path(path_examples).mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AXdcQrkUgUlM",
      "metadata": {
        "id": "AXdcQrkUgUlM"
      },
      "source": [
        "<font size=6> Step #1b: Install and import packages. <font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec5c036",
      "metadata": {
        "id": "eec5c036"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, this cell should install all Python packages you need for each tutorial. </font> <br>\n",
        "<font size=5 color='blue'> If you are running on your own computer, the packages were already installed when you installed the conda environment </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1poqNGJSgKtK",
      "metadata": {
        "id": "1poqNGJSgKtK",
        "outputId": "a33e39f3-2b71-46e5-90e8-eeebfbef6bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Updating the local git repository \n",
            "\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 358 bytes | 6.00 KiB/s, done.\n",
            "From https://github.com/achri19/BAM\n",
            "   c2146f9..5966912  main       -> origin/main\n",
            "Updating c2146f9..5966912\n",
            "Fast-forward\n",
            " notebooks/install_packages_colab_debug.sh | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(mounted_drive)\n",
        "if yes_colab:\n",
        "  if os.path.isdir(mounted_drive / 'BAM'):\n",
        "    print('## Updating the local git repository \\n')\n",
        "    os.chdir(mounted_drive / 'BAM')\n",
        "    # !git add -A \n",
        "    # !git stash\n",
        "    !git pull\n",
        "    # !rm -rf {mounted_drive/'BAM'}\n",
        "\n",
        "  else:\n",
        "    print('## Pulling the git repository with files for the tutorial\\n')\n",
        "    !git clone https://github.com/achri19/BAM.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if yes_colab:\n",
        "  print('\\n## Installing the Python packages needed for these tutorials\\n')\n",
        "  !/bin/bash $mounted_drive/BAM/notebooks/install_packages_colab_debug.sh\n",
        "\n",
        "path_examples = mounted_drive / 'BAM/examples'\n",
        "Path(path_examples).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "m3yYQkp4P_8I",
        "outputId": "ad300b40-715d-4384-d011-8f1632ad16c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m3yYQkp4P_8I",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Installing the Python packages needed for these tutorials\n",
            "\n",
            "(1) Install pip packages to /content/drive/MyDrive/installations\n",
            "nose mpi4py triangle dill Pmw pymetis mpi4py pyproj gdal geemap cmocean geopandas fiona pygeos rasterio rasterstats scikit-fmm rtree pyTMD Orinoco\n",
            "--2023-04-24 22:17:15--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "unlinking: ca-certificates-2023.01.10-h06a4308_0\n",
            "unlinking: certifi-2022.12.7-py37h06a4308_0\n",
            "unlinking: libedit-3.1.20210910-h7f8727e_0\n",
            "unlinking: libffi-3.3-he6710b0_2\n",
            "unlinking: libgcc-ng-9.1.0-hdf63c60_0\n",
            "unlinking: libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "unlinking: ncurses-6.3-h7f8727e_2\n",
            "unlinking: openssl-1.1.1t-h7f8727e_0\n",
            "unlinking: pip-22.3.1-py37h06a4308_0\n",
            "unlinking: python-3.7.13-h12debd9_0\n",
            "unlinking: readline-8.1.2-h7f8727e_1\n",
            "unlinking: setuptools-65.6.3-py37h06a4308_0\n",
            "unlinking: six-1.16.0-pyhd3eb1b0_1\n",
            "unlinking: sqlite-3.38.5-hc218d9a_0\n",
            "unlinking: tk-8.6.12-h1ccaba5_0\n",
            "unlinking: wheel-0.38.4-py37h06a4308_0\n",
            "unlinking: xz-5.2.5-h7f8727e_1\n",
            "unlinking: zlib-1.2.12-h7f8727e_2\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - gdal\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    aws-c-common-0.4.57        |       he6710b0_1         161 KB\n",
            "    libboost-1.73.0            |      h3ff78a5_11        21.3 MB\n",
            "    cffi-1.14.6                |   py36h400218f_0         224 KB\n",
            "    libgdal-3.0.2              |       h7c14f60_1        18.7 MB\n",
            "    numpy-1.19.2               |   py36h54aff64_0          21 KB\n",
            "    zstd-1.4.9                 |       haebb681_0         809 KB\n",
            "    cairo-1.16.0               |       hf32fb01_1         1.5 MB\n",
            "    aws-c-event-stream-0.1.6   |       h2531618_5          25 KB\n",
            "    cryptography-35.0.0        |   py36hd23ed53_0         1.5 MB\n",
            "    mkl_fft-1.3.0              |   py36h54f3939_0         185 KB\n",
            "    sqlite-3.38.2              |       hc218d9a_0         1.5 MB\n",
            "    conda-4.10.3               |   py36h06a4308_0         3.1 MB\n",
            "    numpy-base-1.19.2          |   py36hfa32c7d_0         5.2 MB\n",
            "    tiledb-2.2.9               |       hffe1d7a_0         1.7 MB\n",
            "    aws-sdk-cpp-1.8.185        |       hce553d0_0         2.3 MB\n",
            "    mkl-2020.2                 |              256       213.9 MB\n",
            "    libxml2-2.9.10             |       hb55368b_3         1.3 MB\n",
            "    tk-8.6.11                  |       h1ccaba5_0         3.2 MB\n",
            "    aws-checksums-0.1.9        |       he6710b0_0          51 KB\n",
            "    tqdm-4.63.0                |     pyhd3eb1b0_0          80 KB\n",
            "    gdal-3.0.2                 |   py36h4694593_1         1.5 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    colorama-0.4.4             |     pyhd3eb1b0_0          21 KB\n",
            "    conda-package-handling-1.7.3|   py36h27cfd23_1         946 KB\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
            "    mkl_random-1.1.1           |   py36h0573a6f_0         382 KB\n",
            "    mkl-service-2.3.0          |   py36he8ac12f_0          56 KB\n",
            "    postgresql-12.9            |       hc2c5182_1         4.5 MB\n",
            "    libtiff-4.2.0              |       h85742a9_0         640 KB\n",
            "    libpq-12.9                 |       hc2c5182_1         2.8 MB\n",
            "    libnetcdf-4.6.1            |       h2053bdc_4         1.3 MB\n",
            "    intel-openmp-2020.2        |              254         947 KB\n",
            "    geotiff-1.6.0              |       h21e8280_0         285 KB\n",
            "    libspatialite-4.3.0a       |       h793db0d_0         3.2 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       325.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    aws-c-common:           0.4.57-he6710b0_1      \n",
            "    aws-c-event-stream:     0.1.6-h2531618_5       \n",
            "    aws-checksums:          0.1.9-he6710b0_0       \n",
            "    aws-sdk-cpp:            1.8.185-hce553d0_0     \n",
            "    colorama:               0.4.4-pyhd3eb1b0_0     \n",
            "    conda-package-handling: 1.7.3-py36h27cfd23_1   \n",
            "    postgresql:             12.9-hc2c5182_1        \n",
            "    tqdm:                   4.63.0-pyhd3eb1b0_0    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2023.01.10-h06a4308_0   \n",
            "    certifi:                2018.4.16-py36_0        --> 2021.5.30-py36h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.6-py36h400218f_0   \n",
            "    conda:                  4.5.4-py36_0            --> 4.10.3-py36h06a4308_0   \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 35.0.0-py36hd23ed53_0   \n",
            "    libedit:                3.1.20170329-h6b74fdf_2 --> 3.1.20210910-h7f8727e_0 \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.3-h7f8727e_2          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1t-h7f8727e_0       \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.13-h12debd9_1       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.1.2-h7f8727e_1        \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.38.2-hc218d9a_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.11-h1ccaba5_0       \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7f8727e_1        \n",
            "\n",
            "The following packages will be DOWNGRADED:\n",
            "\n",
            "    cairo:                  1.16.0-h19f5f5c_2       --> 1.16.0-hf32fb01_1       \n",
            "    gdal:                   3.4.1-py37h2c27f0e_0    --> 3.0.2-py36h4694593_1    \n",
            "    geotiff:                1.7.0-hd69d5b1_0        --> 1.6.0-h21e8280_0        \n",
            "    intel-openmp:           2021.4.0-h06a4308_3561  --> 2020.2-254              \n",
            "    libboost:               1.73.0-h28710b8_12      --> 1.73.0-h3ff78a5_11      \n",
            "    libgdal:                3.4.1-hdd9df00_0        --> 3.0.2-h7c14f60_1        \n",
            "    libnetcdf:              4.8.1-h42ceab0_1        --> 4.6.1-h2053bdc_4        \n",
            "    libpq:                  12.9-hc2c5182_2         --> 12.9-hc2c5182_1         \n",
            "    libspatialite:          4.3.0a-hbedb2dc_20      --> 4.3.0a-h793db0d_0       \n",
            "    libtiff:                4.2.0-h2818925_1        --> 4.2.0-h85742a9_0        \n",
            "    libxml2:                2.9.14-h74e7548_0       --> 2.9.10-hb55368b_3       \n",
            "    mkl:                    2021.4.0-h06a4308_640   --> 2020.2-256              \n",
            "    mkl-service:            2.4.0-py37h7f8727e_0    --> 2.3.0-py36he8ac12f_0    \n",
            "    mkl_fft:                1.3.1-py37hd3c417c_0    --> 1.3.0-py36h54f3939_0    \n",
            "    mkl_random:             1.2.2-py37h51133e4_0    --> 1.1.1-py36h0573a6f_0    \n",
            "    numpy:                  1.21.5-py37he7a7128_2   --> 1.19.2-py36h54aff64_0   \n",
            "    numpy-base:             1.21.5-py37hf524024_2   --> 1.19.2-py36hfa32c7d_0   \n",
            "    tiledb:                 2.3.3-h1132f93_2        --> 2.2.9-hffe1d7a_0        \n",
            "    zstd:                   1.5.2-ha4553b6_0        --> 1.4.9-haebb681_0        \n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "(3) Install gdal\n",
            "(4) Install netcdf4\n",
            "(5) Install OpenBlas\n",
            "(6) Install Orinoco\n",
            "(7) Download anuga_core github repository\n",
            "htps://github.com/GeoscienceAustralia/anuga_core\n",
            "fatal: destination path 'anuga_core' already exists and is not an empty directory.\n",
            "(8) Install anuga\n",
            "(7) Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_ancillary = mounted_drive / 'processing/ancillary'\n",
        "path_code = mounted_drive / 'BAM/scripts/'\n",
        "path_templates = mounted_drive /  'BAM/templates/'\n",
        "path_configs = mounted_drive / 'BAM/configs/'\n",
        "sys.path.insert(1,str(path_code))\n",
        "print(path_code)\n",
        "print(path_ancillary)"
      ],
      "metadata": {
        "id": "AWTZh_b8mHoE",
        "outputId": "5912b3a9-09e3-490b-b398-c73978cb39b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AWTZh_b8mHoE",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BAM/scripts\n",
            "/content/drive/MyDrive/processing/ancillary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a749118",
      "metadata": {
        "id": "4a749118",
        "outputId": "59153375-f8db-4e1f-e314-ebe3e50849a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/installations/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
            "  warnings.warn(\n",
            "<ipython-input-6-cb0d4ecab280>:8: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
            "\n",
            "import os\n",
            "os.environ['USE_PYGEOS'] = '0'\n",
            "import geopandas\n",
            "\n",
            "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
            "  import geopandas as gpd\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from string import Template\n",
        "import fnmatch\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from osgeo import gdal \n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rtree\n",
        "from scipy import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyTMD\n"
      ],
      "metadata": {
        "id": "3qUbylPoAJEc"
      },
      "id": "3qUbylPoAJEc",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "CPPe7c_zQ1aE",
      "metadata": {
        "id": "CPPe7c_zQ1aE",
        "outputId": "669da813-f42b-47a8-e299-49daf2a9668e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/BAM/scripts/orinoco_tools.py:42: UserWarning: ShapelyDeprecationWarning\n",
            "  warnings.warn('ShapelyDeprecationWarning')\n",
            "/content/drive/MyDrive/BAM/scripts/orinoco_tools.py:43: UserWarning: UserWarning\n",
            "  warnings.warn('UserWarning')\n"
          ]
        }
      ],
      "source": [
        "from main_tools import (build_directory,\n",
        "                       get_extent_parameters,\n",
        "                       setup_AOI_files, \n",
        "                       make_polygons,\n",
        "                       make_channel_networks,\n",
        "                       make_model_foundation, \n",
        "                       set_boundary_conditions, \n",
        "                       make_watermask,\n",
        "                       more_opening)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3mnrUfhr3NWW",
      "metadata": {
        "id": "3mnrUfhr3NWW"
      },
      "source": [
        "<font size=6> Step #1c: Unzip example files in Komo.zip <font> \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "UnopBCZuT1Es",
      "metadata": {
        "id": "UnopBCZuT1Es"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"komo_starter.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(path_examples)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QgL2wZHj16ze",
      "metadata": {
        "id": "QgL2wZHj16ze"
      },
      "source": [
        "<font size=3> We will access data files stored on a shared Google Drive. You will also need to save files to your own Google Drive.<font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bd01ec",
      "metadata": {
        "id": "c6bd01ec"
      },
      "source": [
        "<font size=6, color ='black' > Step #2: Set the AOI and working directory  </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f2dda11",
      "metadata": {
        "id": "7f2dda11"
      },
      "source": [
        "AOI should match the name of the folder where files will be saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "43f0d63c",
      "metadata": {
        "id": "43f0d63c",
        "scrolled": false,
        "outputId": "ea76e3ed-48e7-484e-d446-1373bf50e925",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Study area is komo\n",
            "Resolution of this setup is 30m\n",
            "\n",
            "\n",
            "\n",
            "##############################################################################################\n",
            "################################[Step 1][Build Directory]#####################################\n",
            "##############################################################################################\n",
            "\n",
            "##################### The working directory set as: \n",
            "\n",
            "/content/drive/MyDrive/BAM/examples/komo\n",
            " \n",
            "##################### Folders are:\n",
            "##################### 0 User_Defined_Files --> User shapefile of model domain and water mask\n",
            "##################### 1 tmp --> For temporary files\n",
            "##################### 3 Meshes --> Where we will build model meshes\n",
            "##################### 4 DEMs --> Where we will build digital elevation models\n",
            "##################### 5 Boundaries --> Where we will store boundary files\n",
            "##################### 6 Simulations --> Where we will run simulations\n",
            "##################### 7 Setup_Files/Setup_SHP --> Shapefiles for setup \n",
            "##################### 8 Setup_Files/Setup_RST --> Rasters for setup\n",
            "##################### 9 Setup_Files/Setup_FIG --> Figures\n",
            "\n",
            "[Step 1][Build Directory] Finished .......\n",
            "\n",
            "/content/drive/MyDrive/BAM/examples/komo\n"
          ]
        }
      ],
      "source": [
        "AOI = 'komo'\n",
        "\n",
        "Path((path_examples / AOI)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "skip = False\n",
        "res = 30 #meters\n",
        "print('\\n')\n",
        "print('Study area is ' + AOI)\n",
        "print('Resolution of this setup is %sm' %(res))\n",
        "\n",
        "working_path,folders = build_directory(path_examples, AOI)\n",
        "working_path = Path(working_path)\n",
        "print(working_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "819f9ee3",
      "metadata": {
        "id": "819f9ee3"
      },
      "source": [
        "<font size='6' > Step #3: Configuration Parameters </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6effe23c",
      "metadata": {
        "id": "6effe23c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    parameters = pd.read_csv(folders[6] / ('config_%s.csv' %(AOI)))\n",
        "except:    \n",
        "    parameters = pd.DataFrame()\n",
        "    parameters['AOI'] = [AOI]\n",
        "    parameters['RiverOceanBoundary'] = '1260'\n",
        "    parameters['Discharge'] = '426'\n",
        "\n",
        "    #Method parameters:\n",
        "    parameters['LandcoverMethod'] = 'WorldCover'\n",
        "    parameters['LandElevMethod'] = 'GLO30'\n",
        "    parameters['OceanElevMethod'] = 'GEBCO'\n",
        "    parameters['LowerRiverElevMethod'] = 'plane'\n",
        "    parameters['UpperRiverElevMethod'] = 'wdpower'\n",
        "    parameters['WetlandElevMethod'] = 'constant_0.5'\n",
        "    parameters['LakeElevMethod'] = 'constant_1'\n",
        "    parameters['ManningLUT'] = 'default'\n",
        "    parameters['WetlandClass'] = '90'\n",
        "\n",
        "    #Coefficients for determining bathymetry:\n",
        "    parameters['WD_POWERA_upper'] = '0.0606'\n",
        "    parameters['WD_POWERB_upper'] = '0.7732'\n",
        "\n",
        "    #Max thresholds:\n",
        "    parameters['MaxOceanDepth'] = '-300'\n",
        "    parameters['MaxNearshoreDepth'] = '-300'\n",
        "    parameters['MaxRiverDepth'] = '-300'\n",
        "    parameters['MaxRiverWidth'] = '756'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"%s/gebco_all.vrt\" %(path_ancillary / \"gebco_2020_geotiff\")\n",
        "#\"%s_GEBCO_%s.tif\" %(folders[8] / AOI,res)\n",
        "from osgeo import gdal\n",
        "gdal.VersionInfo()\n",
        "#!gdalinfo --version"
      ],
      "metadata": {
        "id": "8OC8ohoFBsea",
        "outputId": "7689dc83-ba69-4abb-a907-77602e0d3d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "8OC8ohoFBsea",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3030200'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e36fda",
      "metadata": {
        "id": "77e36fda"
      },
      "outputs": [],
      "source": [
        "EPSG = 32232\n",
        "ulx, uly, lrx, lry = 501790, -2260, 610150, 64700\n",
        "\n",
        "#test = rasterio.open('%s/gebco_all.vrt' %(path_ancillary / \"gebco_2020_geotiff\")).read()\n",
        "os.system('gdalwarp -overwrite -tr %s %s %s/gebco_all.vrt %s_GEBCO_%s.tif '\\\n",
        "                  '-t_srs EPSG:%s -te %s %s %s %s -srcnodata -9999 -dstnodata -9999 -co COMPRESS=DEFLATE '\n",
        "                  %(res,res,path_ancillary / \"gebco_2020_geotiff\",folders[8] / AOI,res,EPSG,ulx,lry,lrx,uly))\n",
        "# ref_10m = rasterio.open('%s_GEBCO_%s.tif' %(folders[8] / AOI,res))\n",
        "\n",
        "# #ref_10m,parameters = get_extent_parameters(path_ancillary,AOI,folders,res,parameters)\n",
        "\n",
        "# os.system('gdalwarp -h')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HHy249g7MZU_",
      "metadata": {
        "id": "HHy249g7MZU_"
      },
      "outputs": [],
      "source": [
        "plt.imshow(ref_10m.read(1),vmin=-50,vmax=0)\n",
        "plt.title('GEBCO Bathymetry resampled to 10m resolution')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16639d91",
      "metadata": {
        "id": "16639d91"
      },
      "source": [
        "<font size='5' color = 'red' > The parameters were saved to a configuration file, we open that here </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d26852d",
      "metadata": {
        "id": "8d26852d"
      },
      "outputs": [],
      "source": [
        "parameters = pd.read_csv(folders[2] / ('%s_Configuration.csv' %(AOI)))\n",
        "print(parameters.iloc[0] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31f780",
      "metadata": {
        "id": "ce31f780"
      },
      "source": [
        "<font size='6' > Step #4: Download datasets </font>\n",
        "<br> Download GEBCO, GLO30, World Cover, and Global Mangrove Maps for the area</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154a55c7",
      "metadata": {
        "id": "154a55c7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "ref = setup_AOI_files(your_path,\n",
        "                    AOI,\n",
        "                    folders,\n",
        "                    res,\n",
        "                    parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96269f27",
      "metadata": {
        "id": "96269f27"
      },
      "source": [
        "<font size='5' color = 'red' > The EPSG coordinate reference system must be is in UTM </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74a3cd0",
      "metadata": {
        "id": "a74a3cd0"
      },
      "outputs": [],
      "source": [
        "EPSG = parameters['EPSG'][0]\n",
        "ulx = parameters['ulx'][0]\n",
        "uly = parameters['uly'][0]\n",
        "lrx = parameters['lrx'][0]\n",
        "lry = parameters['lry'][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771bc90b",
      "metadata": {
        "id": "771bc90b"
      },
      "outputs": [],
      "source": [
        "#ref = rasterio.open('%s/%s_GEBCO_%s.tif' %(folders[8],AOI,res))\n",
        "glo30 = rasterio.open(folders[8] / ('%s_GLO30_topo_%s.tif' %(AOI,res)))\n",
        "landcover = rasterio.open(folders[8] / ('%s_WorldCover_%s.tif' %(AOI,res)))\n",
        "\n",
        "\n",
        "fig,[ax1,ax2] = plt.subplots(nrows=2,figsize=(10,10))\n",
        "ax1.imshow(glo30.read(1),vmin=0,vmax=50,cmap = 'viridis')\n",
        "ax1.set_title('Tandem-X GLO30 Topography at 30m resolution')\n",
        "\n",
        "ax2.imshow(landcover.read(1),cmap='jet_r')\n",
        "ax2.set_title('WorldCover Landcover Map')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QUGJwJOBha8X",
      "metadata": {
        "id": "QUGJwJOBha8X"
      },
      "outputs": [],
      "source": [
        "model_domain = gpd.read_file(folders[7] / ('%s_modeldomain.shp' %(AOI)))\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(10,10))\n",
        "model_domain.geometry.boundary.plot(color=None,edgecolor='red',linewidth = 2,ax=ax,label = 'model domain') #Use your second dataframe\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c1288f",
      "metadata": {
        "id": "88c1288f"
      },
      "source": [
        "<font size='6' > Step #4: Clean the water mask </font> <br>\n",
        "Clean, filter, smooth the water mask you made in the previous notebook </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec50ca1",
      "metadata": {
        "id": "eec50ca1",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#ref_10m = rasterio.open('%s/%s_GEBCO_10.tif' %(folders[8],AOI))\n",
        "watermaskname = make_watermask(path_ancillary, \n",
        "                               AOI,\n",
        "                               folders,\n",
        "                               parameters,\n",
        "                               ref_10m,\n",
        "                               False, \n",
        "                               os.path.isfile('%s_watermask_%s.tif' %(folders[8]/AOI,res)))\n",
        "how_much_opening = 3\n",
        "if os.path.isfile('%s_watermask_%s.tif' %(folders[8]/AOI,30)) == False:\n",
        "    more_opening(AOI,folders,watermaskname,how_much_opening,ref_10m,parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9e534d",
      "metadata": {
        "id": "ae9e534d"
      },
      "outputs": [],
      "source": [
        "print(watermaskname)\n",
        "if res != 10:\n",
        "    os.system('gdalwarp -overwrite -tr %s %s %s %s '\\\n",
        "                      ' -te %s %s %s %s -srcnodata -9999 -dstnodata -9999 -co COMPRESS=DEFLATE -q'\n",
        "                      %(res,res,folders[8]/ (\"%s_watermask_10.tif \" %(AOI)),folders[8] / (\"%s_watermask_%s.tif\" %(AOI,res)),ulx,lry,lrx,uly))\n",
        "    os.system('gdalwarp -overwrite -tr %s %s %s %s '\\\n",
        "                      ' -te %s %s %s %s -srcnodata -9999 -dstnodata -9999 -co COMPRESS=DEFLATE -q'\n",
        "                      %(res,res,folders[8] / (\"%s_landmask_10.tif\" %(AOI)),folders[8] / (\"%s_landmask_%s.tif\" %(AOI,res)),ulx,lry,lrx,uly))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc8cda8",
      "metadata": {
        "id": "ebc8cda8"
      },
      "outputs": [],
      "source": [
        "watermask = rasterio.open(folders[8] / ('%s_watermask_%s.tif' %(AOI,res))).read(1)\n",
        "\n",
        "fig,[ax1,ax2] = plt.subplots(nrows=2,figsize=(15,15))\n",
        "ax1.imshow(watermask,'gray')\n",
        "\n",
        "ax2.imshow(watermask,'gray')\n",
        "ax2.axis([1500,2000, 2000,1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d04ee13",
      "metadata": {
        "id": "1d04ee13"
      },
      "source": [
        "<font size='6' > Step #5: Make polygons of each land cover type <br> </font>\n",
        "Ocean, lake, river, land\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c4bc5e",
      "metadata": {
        "id": "33c4bc5e"
      },
      "outputs": [],
      "source": [
        "make_polygons(AOI,\n",
        "            folders,\n",
        "            parameters,\n",
        "            ref,\n",
        "            watermaskname,\n",
        "            path_templates,\n",
        "            os.path.isfile('%s_lands_%s.tif' %(folders[8]/AOI,res)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da0f719",
      "metadata": {
        "id": "2da0f719"
      },
      "outputs": [],
      "source": [
        "fix,ax = plt.subplots(figsize=(20,20))\n",
        "\n",
        "colors = ['red','blue','orange','cyan','green']\n",
        "polys = ['lands','fullocean','lakes','rivers']\n",
        "i=0\n",
        "for poly in polys:\n",
        "    tmp = gpd.read_file([os.path.join(dirpath,f)\n",
        "            for dirpath,dirnames, files in os.walk(folders[7])\n",
        "            for f in fnmatch.filter(files,'*%s*.shp' %(poly))][0])\n",
        "    tmp.geometry.boundary.plot(color=colors[i], edgecolor=colors[i],linewidth = 1,ax=ax,label = poly) #Use your second dataframe\n",
        "    i=i+1\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29bef3ca",
      "metadata": {
        "id": "29bef3ca"
      },
      "source": [
        "<font size='6' > Step #6: Using Orinoco, get distance and width of the river networks</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73144d89",
      "metadata": {
        "id": "73144d89"
      },
      "outputs": [],
      "source": [
        "segment_width = 150\n",
        "pixel_step = int(round(segment_width/res))\n",
        "try:\n",
        "  distance = gdal.Open('%s_distance_%s.tif' %(folders[8] / AOI,res)).ReadAsArray()\n",
        "  widths = gdal.Open('%s_widths_%sx%s.tif' %(folders[8] / AOI,res,pixel_step)).ReadAsArray()\n",
        "except:\n",
        "  distance,widths = make_channel_networks(folders,\n",
        "                                      AOI,\n",
        "                                      ref,\n",
        "                                      parameters,\n",
        "                                      pixel_step,False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c650374",
      "metadata": {
        "id": "1c650374"
      },
      "source": [
        "<font size='6' > Step #7: Make the Digital Elevation Model </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba2f51e",
      "metadata": {
        "id": "cba2f51e"
      },
      "outputs": [],
      "source": [
        "elevation,elev_name = make_model_foundation(mounted_drive,\n",
        "                                                parameters,\n",
        "                                                AOI,\n",
        "                                                folders,\n",
        "                                                ref,\n",
        "                                                distance,\n",
        "                                                widths,\n",
        "                                                watermask,pixel_step,mounted_drive)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qx3XgmgVSQka",
      "metadata": {
        "id": "Qx3XgmgVSQka"
      },
      "source": [
        "<font size=5 color='green'> We will use the elevation file in later notebooks. </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf09db5",
      "metadata": {
        "id": "daf09db5"
      },
      "outputs": [],
      "source": [
        "print(elev_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fda8ed7",
      "metadata": {
        "id": "2fda8ed7"
      },
      "source": [
        "<font size='6' > Step #6: Clean up temporary files </font> <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641111ed",
      "metadata": {
        "id": "641111ed"
      },
      "outputs": [],
      "source": [
        "cleanup = False \n",
        "if cleanup == True:\n",
        "    print('Cleaning up temporary files')\n",
        "    try:shutil.rmtree(folders[1])\n",
        "    except:''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391dc703",
      "metadata": {
        "id": "391dc703"
      },
      "source": [
        "<font size=5 color='red'> Done building DEM and other ancillary files. Move on to the next notebook 3_GetBoundaries.ipynb </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d42aa06",
      "metadata": {
        "id": "3d42aa06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qXlrDUEBLTjL",
      "metadata": {
        "id": "qXlrDUEBLTjL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}