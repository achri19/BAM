{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "466e2a39",
      "metadata": {
        "id": "466e2a39"
      },
      "source": [
        "<font size=\"8\">Build an ANUGA Model (BAM) </font>\n",
        "\n",
        "<font size=\"3\">In this notebook, we will:\n",
        "\n",
        "- set model configuration parameters\n",
        "\n",
        "- download and preprocess elevation and landcover datasets\n",
        "\n",
        "    \n",
        "- Determine water body polygons\n",
        "\n",
        "\n",
        "- Build the Digital Elevation Model\n",
        "\n",
        "\n",
        "\n",
        "</font>\n",
        "\n",
        "<font size=\"3\">This could take some time, depending on model domain size and complexity of the water mask</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jNhRqEni40KR",
      "metadata": {
        "id": "jNhRqEni40KR"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, set the variable yes_colab = True.</font> <br>\n",
        "<font size=5 color='blue'> If you are running on your own computer, set the variable yes_colab = False </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "gkLaKjYy4_Lv",
      "metadata": {
        "id": "gkLaKjYy4_Lv"
      },
      "outputs": [],
      "source": [
        "yes_colab = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rhp4yA4h2Njc",
      "metadata": {
        "id": "rhp4yA4h2Njc"
      },
      "source": [
        "<font size=6> Step #1a: Set working directory <br> </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JkG2pXof2YoC",
      "metadata": {
        "id": "JkG2pXof2YoC"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, when you run the next cell, a pop-up window will appear asking you to grant access to your Google Drive. You must approve or the notebook will not work. <font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "s_IgSq3RgKtN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_IgSq3RgKtN",
        "outputId": "e22bc0cd-c885-400a-8c62-2f0974214bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Your working directory is /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "your_path = Path(os.getcwd() + '/')\n",
        "if yes_colab:\n",
        "  where_to_mount = '/content/drive/'\n",
        "  from google.colab import drive\n",
        "  drive.mount(where_to_mount, force_remount=True)\n",
        "  mounted_drive = Path(where_to_mount) / 'MyDrive' \n",
        "  sys.path.append(str(mounted_drive / 'installations'))\n",
        "  path_ancillary = mounted_drive / 'ancillary'\n",
        "  Path(mounted_drive / 'installations').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "else:\n",
        "  mounted_drive = Path(os.path.abspath(os.path.join(your_path, os.pardir)))\n",
        "  path_ancillary = mounted_drive / 'BAM/ancillary'\n",
        "\n",
        "print('Your working directory is %s' %(mounted_drive))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AXdcQrkUgUlM",
      "metadata": {
        "id": "AXdcQrkUgUlM"
      },
      "source": [
        "<font size=6> Step #1b: Install and import packages. <font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec5c036",
      "metadata": {
        "id": "eec5c036"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, this cell should install all Python packages you need for each tutorial. </font> <br>\n",
        "<font size=5 color='blue'> If you are running on your own computer, the packages were already installed when you installed the conda environment </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1poqNGJSgKtK",
      "metadata": {
        "id": "1poqNGJSgKtK",
        "outputId": "de32ea3d-afe6-4c3e-b521-d19a24dca701",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Updating the local git repository \n",
            "\n",
            "Saved working directory and index state WIP on main: d4ff054 updated\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(mounted_drive)\n",
        "if yes_colab:\n",
        "  if os.path.isdir(mounted_drive / 'BAM'):\n",
        "    print('## Updating the local git repository \\n')\n",
        "    os.chdir(mounted_drive / 'BAM')\n",
        "    #!git fsck --full\n",
        "    # !git add -A \n",
        "    !git stash   \n",
        "    !git pull\n",
        "    # !rm -rf {mounted_drive/'BAM'}\n",
        "\n",
        "  else:\n",
        "    print('## Pulling the git repository with files for the tutorial\\n')\n",
        "    !git clone https://github.com/achri19/BAM.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if yes_colab:\n",
        "  print('\\n## Installing the Python packages needed for these tutorials\\n')\n",
        "  !/bin/bash $mounted_drive/BAM/notebooks/install_packages_colab_debug.sh\n"
      ],
      "metadata": {
        "id": "m3yYQkp4P_8I",
        "outputId": "2d8b3231-ed97-4cd3-b675-da30bc8fd6b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "m3yYQkp4P_8I",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Installing the Python packages needed for these tutorials\n",
            "\n",
            "(1) Install pip packages to /content/drive/MyDrive/installations\n",
            "nose mpi4py triangle dill Pmw pymetis mpi4py pyproj gdal geemap cmocean geopandas fiona pygeos rasterio rasterstats scikit-fmm rtree pyTMD Orinoco\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nose\n",
            "  Using cached nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "Collecting rtree\n",
            "  Using cached Rtree-1.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Collecting shapely\n",
            "  Using cached shapely-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "Collecting mpi4py\n",
            "  Using cached mpi4py-3.1.4-cp39-cp39-linux_x86_64.whl\n",
            "Collecting triangle\n",
            "  Using cached triangle-20220202-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Collecting dill\n",
            "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "Collecting Pmw\n",
            "  Using cached Pmw-2.1.1-py3-none-any.whl\n",
            "Collecting pymetis\n",
            "  Using cached PyMetis-2023.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "Collecting geemap\n",
            "  Using cached geemap-0.20.6-py2.py3-none-any.whl (2.2 MB)\n",
            "Collecting cmocean\n",
            "  Using cached cmocean-3.0.3-py3-none-any.whl (222 kB)\n",
            "Collecting geopandas\n",
            "  Using cached geopandas-0.12.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting netCDF4\n",
            "  Using cached netCDF4-1.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "Collecting pyproj\n",
            "  Using cached pyproj-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "Collecting fiona\n",
            "  Using cached Fiona-1.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "Collecting pygeos\n",
            "  Using cached pygeos-0.14-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Collecting rasterio\n",
            "  Using cached rasterio-1.3.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
            "Collecting rasterstats\n",
            "  Using cached rasterstats-0.18.0-py3-none-any.whl (17 kB)\n",
            "Collecting scikit-fmm\n",
            "  Using cached scikit_fmm-2023.4.2-cp39-cp39-linux_x86_64.whl\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "Collecting backports.zoneinfo\n",
            "  Using cached backports.zoneinfo-0.2.1-cp39-cp39-linux_x86_64.whl\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting six\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting ipyfilechooser>=0.6.0\n",
            "  Using cached ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting geocoder\n",
            "  Using cached geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "Collecting ipytree\n",
            "  Using cached ipytree-0.2.2-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting plotly\n",
            "  Using cached plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "Collecting pyperclip\n",
            "  Using cached pyperclip-1.8.2-py3-none-any.whl\n",
            "Collecting scooby\n",
            "  Using cached scooby-0.7.1-py3-none-any.whl (16 kB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Collecting folium>=0.13.0\n",
            "  Using cached folium-0.14.0-py2.py3-none-any.whl (102 kB)\n",
            "Collecting bqplot\n",
            "  Using cached bqplot-0.12.39-py2.py3-none-any.whl (1.2 MB)\n",
            "Collecting eerepr>=0.0.4\n",
            "  Using cached eerepr-0.0.4-py3-none-any.whl (9.7 kB)\n",
            "Collecting python-box\n",
            "  Using cached python_box-7.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.2 MB)\n",
            "Collecting colour\n",
            "  Using cached colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Collecting ipyleaflet>=0.17.0\n",
            "  Using cached ipyleaflet-0.17.2-py3-none-any.whl (3.7 MB)\n",
            "Collecting earthengine-api>=0.1.347\n",
            "  Using cached earthengine_api-0.1.350-py3-none-any.whl\n",
            "Collecting ipyevents\n",
            "  Using cached ipyevents-2.0.1-py2.py3-none-any.whl (130 kB)\n",
            "Collecting packaging\n",
            "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
            "Collecting cftime\n",
            "  Using cached cftime-1.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting certifi\n",
            "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "Collecting click-plugins>=1.0\n",
            "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting munch>=2.3.2\n",
            "  Using cached munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting attrs>=19.2.0\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting importlib-metadata\n",
            "  Using cached importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting click~=8.0\n",
            "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Collecting affine\n",
            "  Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-67.7.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Using cached snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting simplejson\n",
            "  Using cached simplejson-3.19.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "Collecting fiona\n",
            "  Using cached Fiona-1.8.22-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "Collecting google-api-python-client>=1.12.1\n",
            "  Using cached google_api_python_client-2.86.0-py2.py3-none-any.whl (11.3 MB)\n",
            "Collecting google-auth>=1.4.1\n",
            "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
            "Collecting requests\n",
            "  Using cached requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "Collecting google-auth-httplib2>=0.0.3\n",
            "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-cloud-storage\n",
            "  Using cached google_cloud_storage-2.8.0-py2.py3-none-any.whl (113 kB)\n",
            "Collecting httplib2<1dev,>=0.9.2\n",
            "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Collecting branca>=0.6.0\n",
            "  Using cached branca-0.6.0-py3-none-any.whl (24 kB)\n",
            "Collecting jinja2>=2.9\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Collecting ipywidgets\n",
            "  Using cached ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
            "Collecting traittypes<3,>=0.2.1\n",
            "  Using cached traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting xyzservices>=2021.8.1\n",
            "  Using cached xyzservices-2023.2.0-py3-none-any.whl (55 kB)\n",
            "Collecting pyparsing>=2.1.6\n",
            "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Collecting traitlets>=4.3.0\n",
            "  Using cached traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "Collecting ratelim\n",
            "  Using cached ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Collecting future\n",
            "  Using cached future-0.18.3-py3-none-any.whl\n",
            "Collecting zipp>=0.5\n",
            "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting importlib-resources>=3.2.0\n",
            "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "Collecting pillow>=6.2.0\n",
            "  Using cached Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Using cached fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Using cached kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
            "  Using cached google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
            "Collecting uritemplate<5,>=3.0.1\n",
            "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting jupyterlab-widgets~=3.0.7\n",
            "  Using cached jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
            "Collecting ipykernel>=4.5.1\n",
            "  Using cached ipykernel-6.22.0-py3-none-any.whl (149 kB)\n",
            "Collecting ipython>=6.1.0\n",
            "  Using cached ipython-8.12.0-py3-none-any.whl (796 kB)\n",
            "Collecting widgetsnbextension~=4.0.7\n",
            "  Using cached widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Using cached MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
            "  Using cached google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-resumable-media>=2.3.2\n",
            "  Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Using cached charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "Collecting decorator\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5\n",
            "  Using cached protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Using cached googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Collecting matplotlib-inline>=0.1\n",
            "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting tornado>=6.1\n",
            "  Using cached tornado-6.3.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
            "Collecting comm>=0.1.1\n",
            "  Using cached comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
            "Collecting pyzmq>=20\n",
            "  Using cached pyzmq-25.0.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Collecting psutil\n",
            "  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12\n",
            "  Using cached jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n",
            "Collecting nest-asyncio\n",
            "  Using cached nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting debugpy>=1.6.5\n",
            "  Using cached debugpy-1.6.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Collecting jupyter-client>=6.1.12\n",
            "  Using cached jupyter_client-8.2.0-py3-none-any.whl (103 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "Collecting stack-data\n",
            "  Using cached stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting backcall\n",
            "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting typing-extensions\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Using cached jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting pygments>=2.4.0\n",
            "  Using cached Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "Collecting pickleshare\n",
            "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
            "  Using cached prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0\n",
            "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "Collecting platformdirs>=2.5\n",
            "  Using cached platformdirs-3.4.0-py3-none-any.whl (15 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Using cached wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Using cached executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Using cached asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pure-eval\n",
            "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, pytz, pyperclip, pure-eval, ptyprocess, Pmw, pickleshare, nose, executing, colour, backcall, zipp, xyzservices, widgetsnbextension, urllib3, uritemplate, tzdata, typing-extensions, traitlets, tornado, tenacity, six, simplejson, setuptools, scooby, rtree, pyzmq, python-box, pyparsing, pygments, pyasn1, psutil, protobuf, prompt-toolkit, platformdirs, pillow, pexpect, parso, packaging, numpy, nest-asyncio, mpi4py, MarkupSafe, kiwisolver, jupyterlab-widgets, idna, google-crc32c, future, fonttools, dill, decorator, debugpy, cycler, click, charset-normalizer, certifi, cachetools, backports.zoneinfo, attrs, affine, triangle, traittypes, snuggs, shapely, scipy, scikit-fmm, rsa, requests, ratelim, python-dateutil, pyproj, pymetis, pygeos, pyasn1-modules, plotly, munch, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib-metadata, httplib2, googleapis-common-protos, google-resumable-media, contourpy, comm, cligj, click-plugins, cftime, asttokens, stack-data, rasterio, pandas, netCDF4, matplotlib, jupyter-client, google-auth, geocoder, fiona, branca, rasterstats, ipython, google-auth-httplib2, google-api-core, geopandas, folium, cmocean, ipykernel, google-cloud-core, google-api-python-client, ipywidgets, google-cloud-storage, ipytree, ipyleaflet, ipyfilechooser, ipyevents, earthengine-api, bqplot, eerepr, geemap\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel~=5.5.6, but you have ipykernel 6.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.34.0, but you have ipython 8.12.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 Pmw-2.1.1 affine-2.4.0 asttokens-2.2.1 attrs-23.1.0 backcall-0.2.0 backports.zoneinfo-0.2.1 bqplot-0.12.39 branca-0.6.0 cachetools-5.3.0 certifi-2022.12.7 cftime-1.6.2 charset-normalizer-3.1.0 click-8.1.3 click-plugins-1.1.1 cligj-0.7.2 cmocean-3.0.3 colour-0.1.5 comm-0.1.3 contourpy-1.0.7 cycler-0.11.0 debugpy-1.6.7 decorator-5.1.1 dill-0.3.6 earthengine-api-0.1.350 eerepr-0.0.4 executing-1.2.0 fiona-1.8.22 folium-0.14.0 fonttools-4.39.3 future-0.18.3 geemap-0.20.6 geocoder-1.38.1 geopandas-0.12.2 google-api-core-2.11.0 google-api-python-client-2.86.0 google-auth-2.17.3 google-auth-httplib2-0.1.0 google-cloud-core-2.3.2 google-cloud-storage-2.8.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.59.0 httplib2-0.22.0 idna-3.4 importlib-metadata-6.6.0 importlib-resources-5.12.0 ipyevents-2.0.1 ipyfilechooser-0.6.0 ipykernel-6.22.0 ipyleaflet-0.17.2 ipython-8.12.0 ipytree-0.2.2 ipywidgets-8.0.6 jedi-0.18.2 jinja2-3.1.2 jupyter-client-8.2.0 jupyter-core-5.3.0 jupyterlab-widgets-3.0.7 kiwisolver-1.4.4 matplotlib-3.7.1 matplotlib-inline-0.1.6 mpi4py-3.1.4 munch-2.5.0 nest-asyncio-1.5.6 netCDF4-1.6.3 nose-1.3.7 numpy-1.24.3 packaging-23.1 pandas-2.0.1 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.5.0 platformdirs-3.4.0 plotly-5.14.1 prompt-toolkit-3.0.38 protobuf-4.22.3 psutil-5.9.5 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.5.0 pyasn1-modules-0.3.0 pygeos-0.14 pygments-2.15.1 pymetis-2023.1 pyparsing-3.0.9 pyperclip-1.8.2 pyproj-3.5.0 python-box-7.0.1 python-dateutil-2.8.2 pytz-2023.3 pyzmq-25.0.2 rasterio-1.3.6 rasterstats-0.18.0 ratelim-0.1.6 requests-2.29.0 rsa-4.9 rtree-1.0.1 scikit-fmm-2023.4.2 scipy-1.10.1 scooby-0.7.1 setuptools-67.7.2 shapely-2.0.1 simplejson-3.19.1 six-1.16.0 snuggs-1.4.7 stack-data-0.6.2 tenacity-8.2.2 tornado-6.3.1 traitlets-5.9.0 traittypes-0.2.1 triangle-20220202 typing-extensions-4.5.0 tzdata-2023.3 uritemplate-4.1.1 urllib3-1.26.15 wcwidth-0.2.6 widgetsnbextension-4.0.7 xyzservices-2023.2.0 zipp-3.15.0\n",
            "(3) Install gdal\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "gdal-bin is already the newest version (3.3.2+dfsg-2~focal2).\n",
            "python3-gdal is already the newest version (3.3.2+dfsg-2~focal2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "(6) Install Orinoco\n",
            "(7) Download anuga_core github repository\n",
            "htps://github.com/GeoscienceAustralia/anuga_core\n",
            "fatal: destination path 'anuga_core' already exists and is not an empty directory.\n",
            "(8) Install anuga\n",
            "(7) Completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_ancillary = mounted_drive / 'processing/ancillary'\n",
        "path_code = mounted_drive / 'BAM/scripts/'\n",
        "path_templates = mounted_drive /  'BAM/templates/'\n",
        "path_configs = mounted_drive / 'BAM/configs/'\n",
        "sys.path.insert(1,str(path_code))\n",
        "print(path_code)\n",
        "print(path_ancillary)\n",
        "\n",
        "path_examples = mounted_drive / 'BAM/examples'\n",
        "Path(path_examples).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "AWTZh_b8mHoE",
        "outputId": "22a01d46-e515-45b5-8413-94e02c795836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AWTZh_b8mHoE",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BAM/scripts\n",
            "/content/drive/MyDrive/processing/ancillary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a749118",
      "metadata": {
        "id": "4a749118",
        "outputId": "55a93e0a-5080-4f6d-f896-d0fd98f0dcc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/installations/geopandas/_compat.py:123: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
            "  warnings.warn(\n",
            "<ipython-input-6-cb0d4ecab280>:8: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
            "\n",
            "import os\n",
            "os.environ['USE_PYGEOS'] = '0'\n",
            "import geopandas\n",
            "\n",
            "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
            "  import geopandas as gpd\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from string import Template\n",
        "import fnmatch\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from osgeo import gdal \n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rtree\n",
        "from scipy import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "CPPe7c_zQ1aE",
      "metadata": {
        "id": "CPPe7c_zQ1aE"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import pyTMD\n",
        "except:\n",
        "  !pip install pytmd\n",
        "\n",
        "from main_tools import (build_directory,\n",
        "                       get_extent_parameters,\n",
        "                       setup_AOI_files, \n",
        "                       make_polygons,\n",
        "                       make_channel_networks,\n",
        "                       make_model_foundation, \n",
        "                       set_boundary_conditions, \n",
        "                       make_watermask,\n",
        "                       more_opening)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3mnrUfhr3NWW",
      "metadata": {
        "id": "3mnrUfhr3NWW"
      },
      "source": [
        "<font size=6> Step #1c: Unzip example files in Komo.zip <font> \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "UnopBCZuT1Es",
      "metadata": {
        "id": "UnopBCZuT1Es"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"komo_starter.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(path_examples)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QgL2wZHj16ze",
      "metadata": {
        "id": "QgL2wZHj16ze"
      },
      "source": [
        "<font size=3> We will access data files stored on a shared Google Drive. You will also need to save files to your own Google Drive.<font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bd01ec",
      "metadata": {
        "id": "c6bd01ec"
      },
      "source": [
        "<font size=6, color ='black' > Step #2: Set the AOI and working directory  </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f2dda11",
      "metadata": {
        "id": "7f2dda11"
      },
      "source": [
        "AOI should match the name of the folder where files will be saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "43f0d63c",
      "metadata": {
        "id": "43f0d63c",
        "scrolled": false,
        "outputId": "79a712f8-a2ed-489b-c344-5a8054032e8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Study area is komo\n",
            "Resolution of this setup is 30m\n",
            "\n",
            "\n",
            "\n",
            "##############################################################################################\n",
            "################################[Step 1][Build Directory]#####################################\n",
            "##############################################################################################\n",
            "\n",
            "##################### The working directory set as: \n",
            "\n",
            "/content/drive/MyDrive/BAM/examples/komo\n",
            " \n",
            "##################### Folders are:\n",
            "##################### 0 User_Defined_Files --> User shapefile of model domain and water mask\n",
            "##################### 1 tmp --> For temporary files\n",
            "##################### 3 Meshes --> Where we will build model meshes\n",
            "##################### 4 DEMs --> Where we will build digital elevation models\n",
            "##################### 5 Boundaries --> Where we will store boundary files\n",
            "##################### 6 Simulations --> Where we will run simulations\n",
            "##################### 7 Setup_Files/Setup_SHP --> Shapefiles for setup \n",
            "##################### 8 Setup_Files/Setup_RST --> Rasters for setup\n",
            "##################### 9 Setup_Files/Setup_FIG --> Figures\n",
            "\n",
            "[Step 1][Build Directory] Finished .......\n",
            "\n",
            "/content/drive/MyDrive/BAM/examples/komo\n"
          ]
        }
      ],
      "source": [
        "AOI = 'komo'\n",
        "\n",
        "Path((path_examples / AOI)).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "skip = False\n",
        "res = 30 #meters\n",
        "print('\\n')\n",
        "print('Study area is ' + AOI)\n",
        "print('Resolution of this setup is %sm' %(res))\n",
        "\n",
        "working_path,folders = build_directory(path_examples, AOI)\n",
        "working_path = Path(working_path)\n",
        "print(working_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "819f9ee3",
      "metadata": {
        "id": "819f9ee3"
      },
      "source": [
        "<font size='6' > Step #3: Configuration Parameters </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6effe23c",
      "metadata": {
        "id": "6effe23c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    parameters = pd.read_csv(folders[6] / ('config_%s.csv' %(AOI)))\n",
        "except:    \n",
        "    parameters = pd.DataFrame()\n",
        "    parameters['AOI'] = [AOI]\n",
        "    parameters['RiverOceanBoundary'] = '1260'\n",
        "    parameters['Discharge'] = '426'\n",
        "\n",
        "    #Method parameters:\n",
        "    parameters['LandcoverMethod'] = 'WorldCover'\n",
        "    parameters['LandElevMethod'] = 'GLO30'\n",
        "    parameters['OceanElevMethod'] = 'GEBCO'\n",
        "    parameters['LowerRiverElevMethod'] = 'plane'\n",
        "    parameters['UpperRiverElevMethod'] = 'wdpower'\n",
        "    parameters['WetlandElevMethod'] = 'constant_0.5'\n",
        "    parameters['LakeElevMethod'] = 'constant_1'\n",
        "    parameters['ManningLUT'] = 'default'\n",
        "    parameters['WetlandClass'] = '90'\n",
        "\n",
        "    #Coefficients for determining bathymetry:\n",
        "    parameters['WD_POWERA_upper'] = '0.0606'\n",
        "    parameters['WD_POWERB_upper'] = '0.7732'\n",
        "\n",
        "    #Max thresholds:\n",
        "    parameters['MaxOceanDepth'] = '-300'\n",
        "    parameters['MaxNearshoreDepth'] = '-300'\n",
        "    parameters['MaxRiverDepth'] = '-300'\n",
        "    parameters['MaxRiverWidth'] = '756'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"%s/gebco_all.vrt\" %(path_ancillary / \"gebco_2020_geotiff\")\n",
        "#\"%s_GEBCO_%s.tif\" %(folders[8] / AOI,res)\n",
        "from osgeo import gdal\n",
        "gdal.VersionInfo()\n",
        "#!gdalinfo --version"
      ],
      "metadata": {
        "id": "8OC8ohoFBsea",
        "outputId": "01c5c6e5-4160-49d2-9934-52accb0fbaef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "8OC8ohoFBsea",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3030200'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "77e36fda",
      "metadata": {
        "id": "77e36fda",
        "outputId": "70709d5b-fed9-4772-ba61-cccbb35f3345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/processing/ancillary/gebco/gebco_all.vrt\n"
          ]
        }
      ],
      "source": [
        "EPSG = 32232\n",
        "ulx, uly, lrx, lry = 501790, -2260, 610150, 64700\n",
        "ref_res = res\n",
        "input_path = path_ancillary\n",
        "delta = AOI\n",
        "# #test = rasterio.open('%s/gebco_all.vrt' %(path_ancillary / \"gebco_2020_geotiff\")).read()\n",
        "os.system('gdalwarp -overwrite -tr %s %s %s/gebco_all.vrt %s_GEBCO_%s.tif '\\\n",
        "                  '-t_srs EPSG:%s -te %s %s %s %s -srcnodata -9999 -dstnodata -9999 -co COMPRESS=DEFLATE'\n",
        "                   %(ref_res,ref_res,input_path / \"gebco\",folders[8] / delta,ref_res,EPSG,ulx,lry,lrx,uly))\n",
        "# # ref_10m = rasterio.open('%s_GEBCO_%s.tif' %(folders[8] / AOI,res))\n",
        "\n",
        "# ref_10m,parameters = get_extent_parameters(path_ancillary,AOI,folders,res,parameters)\n",
        "\n",
        "# os.system('gdalwarp -h')\n",
        "# print('%s/gebco_all.vrt' %(input_path / \"gebco\"))\n",
        "\n",
        "test = gdal.Open('%s/gebco_all.vrt' %(input_path / \"gebco\"))\n",
        "print('%s/gebco_all.vrt' %(input_path / \"gebco\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HHy249g7MZU_",
      "metadata": {
        "id": "HHy249g7MZU_"
      },
      "outputs": [],
      "source": [
        "plt.imshow(ref_10m.read(1),vmin=-50,vmax=0)\n",
        "plt.title('GEBCO Bathymetry resampled to 10m resolution')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16639d91",
      "metadata": {
        "id": "16639d91"
      },
      "source": [
        "<font size='5' color = 'red' > The parameters were saved to a configuration file, we open that here </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d26852d",
      "metadata": {
        "id": "8d26852d"
      },
      "outputs": [],
      "source": [
        "parameters = pd.read_csv(folders[2] / ('%s_Configuration.csv' %(AOI)))\n",
        "print(parameters.iloc[0] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31f780",
      "metadata": {
        "id": "ce31f780"
      },
      "source": [
        "<font size='6' > Step #4: Download datasets </font>\n",
        "<br> Download GEBCO, GLO30, World Cover, and Global Mangrove Maps for the area</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "154a55c7",
      "metadata": {
        "id": "154a55c7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "ref = setup_AOI_files(your_path,\n",
        "                    AOI,\n",
        "                    folders,\n",
        "                    res,\n",
        "                    parameters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96269f27",
      "metadata": {
        "id": "96269f27"
      },
      "source": [
        "<font size='5' color = 'red' > The EPSG coordinate reference system must be is in UTM </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a74a3cd0",
      "metadata": {
        "id": "a74a3cd0"
      },
      "outputs": [],
      "source": [
        "EPSG = parameters['EPSG'][0]\n",
        "ulx = parameters['ulx'][0]\n",
        "uly = parameters['uly'][0]\n",
        "lrx = parameters['lrx'][0]\n",
        "lry = parameters['lry'][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "771bc90b",
      "metadata": {
        "id": "771bc90b"
      },
      "outputs": [],
      "source": [
        "#ref = rasterio.open('%s/%s_GEBCO_%s.tif' %(folders[8],AOI,res))\n",
        "glo30 = rasterio.open(folders[8] / ('%s_GLO30_topo_%s.tif' %(AOI,res)))\n",
        "landcover = rasterio.open(folders[8] / ('%s_WorldCover_%s.tif' %(AOI,res)))\n",
        "\n",
        "\n",
        "fig,[ax1,ax2] = plt.subplots(nrows=2,figsize=(10,10))\n",
        "ax1.imshow(glo30.read(1),vmin=0,vmax=50,cmap = 'viridis')\n",
        "ax1.set_title('Tandem-X GLO30 Topography at 30m resolution')\n",
        "\n",
        "ax2.imshow(landcover.read(1),cmap='jet_r')\n",
        "ax2.set_title('WorldCover Landcover Map')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QUGJwJOBha8X",
      "metadata": {
        "id": "QUGJwJOBha8X"
      },
      "outputs": [],
      "source": [
        "model_domain = gpd.read_file(folders[7] / ('%s_modeldomain.shp' %(AOI)))\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(10,10))\n",
        "model_domain.geometry.boundary.plot(color=None,edgecolor='red',linewidth = 2,ax=ax,label = 'model domain') #Use your second dataframe\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c1288f",
      "metadata": {
        "id": "88c1288f"
      },
      "source": [
        "<font size='6' > Step #4: Clean the water mask </font> <br>\n",
        "Clean, filter, smooth the water mask you made in the previous notebook </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec50ca1",
      "metadata": {
        "id": "eec50ca1",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#ref_10m = rasterio.open('%s/%s_GEBCO_10.tif' %(folders[8],AOI))\n",
        "watermaskname = make_watermask(path_ancillary, \n",
        "                               AOI,\n",
        "                               folders,\n",
        "                               parameters,\n",
        "                               ref_10m,\n",
        "                               False, \n",
        "                               os.path.isfile('%s_watermask_%s.tif' %(folders[8]/AOI,res)))\n",
        "how_much_opening = 3\n",
        "if os.path.isfile('%s_watermask_%s.tif' %(folders[8]/AOI,30)) == False:\n",
        "    more_opening(AOI,folders,watermaskname,how_much_opening,ref_10m,parameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9e534d",
      "metadata": {
        "id": "ae9e534d"
      },
      "outputs": [],
      "source": [
        "print(watermaskname)\n",
        "if res != 10:\n",
        "    os.system('gdalwarp -overwrite -tr %s %s %s %s '\\\n",
        "                      ' -te %s %s %s %s -srcnodata -9999 -dstnodata -9999 -co COMPRESS=DEFLATE -q'\n",
        "                      %(res,res,folders[8]/ (\"%s_watermask_10.tif \" %(AOI)),folders[8] / (\"%s_watermask_%s.tif\" %(AOI,res)),ulx,lry,lrx,uly))\n",
        "    os.system('gdalwarp -overwrite -tr %s %s %s %s '\\\n",
        "                      ' -te %s %s %s %s -srcnodata -9999 -dstnodata -9999 -co COMPRESS=DEFLATE -q'\n",
        "                      %(res,res,folders[8] / (\"%s_landmask_10.tif\" %(AOI)),folders[8] / (\"%s_landmask_%s.tif\" %(AOI,res)),ulx,lry,lrx,uly))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc8cda8",
      "metadata": {
        "id": "ebc8cda8"
      },
      "outputs": [],
      "source": [
        "watermask = rasterio.open(folders[8] / ('%s_watermask_%s.tif' %(AOI,res))).read(1)\n",
        "\n",
        "fig,[ax1,ax2] = plt.subplots(nrows=2,figsize=(15,15))\n",
        "ax1.imshow(watermask,'gray')\n",
        "\n",
        "ax2.imshow(watermask,'gray')\n",
        "ax2.axis([1500,2000, 2000,1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d04ee13",
      "metadata": {
        "id": "1d04ee13"
      },
      "source": [
        "<font size='6' > Step #5: Make polygons of each land cover type <br> </font>\n",
        "Ocean, lake, river, land\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33c4bc5e",
      "metadata": {
        "id": "33c4bc5e"
      },
      "outputs": [],
      "source": [
        "make_polygons(AOI,\n",
        "            folders,\n",
        "            parameters,\n",
        "            ref,\n",
        "            watermaskname,\n",
        "            path_templates,\n",
        "            os.path.isfile('%s_lands_%s.tif' %(folders[8]/AOI,res)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da0f719",
      "metadata": {
        "id": "2da0f719"
      },
      "outputs": [],
      "source": [
        "fix,ax = plt.subplots(figsize=(20,20))\n",
        "\n",
        "colors = ['red','blue','orange','cyan','green']\n",
        "polys = ['lands','fullocean','lakes','rivers']\n",
        "i=0\n",
        "for poly in polys:\n",
        "    tmp = gpd.read_file([os.path.join(dirpath,f)\n",
        "            for dirpath,dirnames, files in os.walk(folders[7])\n",
        "            for f in fnmatch.filter(files,'*%s*.shp' %(poly))][0])\n",
        "    tmp.geometry.boundary.plot(color=colors[i], edgecolor=colors[i],linewidth = 1,ax=ax,label = poly) #Use your second dataframe\n",
        "    i=i+1\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29bef3ca",
      "metadata": {
        "id": "29bef3ca"
      },
      "source": [
        "<font size='6' > Step #6: Using Orinoco, get distance and width of the river networks</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73144d89",
      "metadata": {
        "id": "73144d89"
      },
      "outputs": [],
      "source": [
        "segment_width = 150\n",
        "pixel_step = int(round(segment_width/res))\n",
        "try:\n",
        "  distance = gdal.Open('%s_distance_%s.tif' %(folders[8] / AOI,res)).ReadAsArray()\n",
        "  widths = gdal.Open('%s_widths_%sx%s.tif' %(folders[8] / AOI,res,pixel_step)).ReadAsArray()\n",
        "except:\n",
        "  distance,widths = make_channel_networks(folders,\n",
        "                                      AOI,\n",
        "                                      ref,\n",
        "                                      parameters,\n",
        "                                      pixel_step,False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c650374",
      "metadata": {
        "id": "1c650374"
      },
      "source": [
        "<font size='6' > Step #7: Make the Digital Elevation Model </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cba2f51e",
      "metadata": {
        "id": "cba2f51e"
      },
      "outputs": [],
      "source": [
        "elevation,elev_name = make_model_foundation(mounted_drive,\n",
        "                                                parameters,\n",
        "                                                AOI,\n",
        "                                                folders,\n",
        "                                                ref,\n",
        "                                                distance,\n",
        "                                                widths,\n",
        "                                                watermask,pixel_step,mounted_drive)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qx3XgmgVSQka",
      "metadata": {
        "id": "Qx3XgmgVSQka"
      },
      "source": [
        "<font size=5 color='green'> We will use the elevation file in later notebooks. </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf09db5",
      "metadata": {
        "id": "daf09db5"
      },
      "outputs": [],
      "source": [
        "print(elev_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fda8ed7",
      "metadata": {
        "id": "2fda8ed7"
      },
      "source": [
        "<font size='6' > Step #6: Clean up temporary files </font> <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641111ed",
      "metadata": {
        "id": "641111ed"
      },
      "outputs": [],
      "source": [
        "cleanup = False \n",
        "if cleanup == True:\n",
        "    print('Cleaning up temporary files')\n",
        "    try:shutil.rmtree(folders[1])\n",
        "    except:''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "391dc703",
      "metadata": {
        "id": "391dc703"
      },
      "source": [
        "<font size=5 color='red'> Done building DEM and other ancillary files. Move on to the next notebook 3_GetBoundaries.ipynb </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d42aa06",
      "metadata": {
        "id": "3d42aa06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qXlrDUEBLTjL",
      "metadata": {
        "id": "qXlrDUEBLTjL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}