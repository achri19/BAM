{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achri19/BAM/blob/main/notebooks/1_Downloading_AncillaryData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "466e2a39"
      },
      "source": [
        "<font size=\"8\">Preparations: Downloading Ancillary Data</font>\n",
        "\n",
        "<font size=\"3\">In this notebook, we will:\n",
        "\n",
        "- Download GEBCO, Global Mangrove Watch, and Geoid datasets that are needed for the tutorials.\n",
        "- You only need to run this notebook once to download the files, but it will take a long time and requires 15+ GB of space on your hard drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNhRqEni40KR"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, set the variable yes_colab = True.</font> <br>\n",
        "<font size=5 color='blue'> If you are running on your own computer, set the variable yes_colab = False </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gkLaKjYy4_Lv"
      },
      "outputs": [],
      "source": [
        "yes_colab = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhp4yA4h2Njc"
      },
      "source": [
        "<font size=6> Step #1: Set working directory <br> </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkG2pXof2YoC"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, when you run the next cell, a pop-up window will appear asking you to grant access to your Google Drive. You must approve or the notebook will not work. <font> <br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_IgSq3RgKtN",
        "outputId": "1f7b33ce-4d14-43cf-ab11-4263c93c9904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Your working directory is /content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "your_path = Path(os.getcwd() + '/')\n",
        "if yes_colab:\n",
        "  where_to_mount = '/content/drive/'\n",
        "  from google.colab import drive\n",
        "  drive.mount(where_to_mount, force_remount=True)\n",
        "  mounted_drive = Path(where_to_mount) / 'MyDrive'\n",
        "  sys.path.append(str(mounted_drive / 'installations'))\n",
        "  path_ancillary = mounted_drive / 'ancillary'\n",
        "  Path(mounted_drive / 'installations').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "else:\n",
        "  mounted_drive = Path(os.path.abspath(os.path.join(your_path, os.pardir)))\n",
        "  path_ancillary = mounted_drive / 'ancillary'\n",
        "\n",
        "print('Your working directory is %s' %(mounted_drive))\n",
        "\n",
        "os.chdir(mounted_drive)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXdcQrkUgUlM"
      },
      "source": [
        "<font size=6> Step #2: Install and import packages. <font> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eec5c036"
      },
      "source": [
        "<font size=5 color='green'> If you are running in Google Colab, this cell should install all Python packages you need for each tutorial. </font> <br>\n",
        "<font size=5 color='blue'> If you are running on your own computer, the packages were already installed when you installed the conda environment </font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1poqNGJSgKtK",
        "outputId": "d3f08fb3-f500-494b-ae83-6b1c693674c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Updating the local git repository \n",
            "\n",
            "Saved working directory and index state WIP on main: 1d3e672 Merge pull request #8 from achri19/achri19-patch-7\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), 5.05 KiB | 94.00 KiB/s, done.\n",
            "From https://github.com/achri19/BAM\n",
            "   1d3e672..65840a0  main       -> origin/main\n",
            "Updating 1d3e672..65840a0\n",
            "Fast-forward\n",
            " notebooks/1_Downloading_AncillaryData.ipynb | 954 \u001b[32m++++++++++++++++++++++++++\u001b[m\u001b[31m----------------------\u001b[m\n",
            " 1 file changed, 510 insertions(+), 444 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "if yes_colab:\n",
        "  if os.path.isdir(mounted_drive / 'BAM'):\n",
        "    print('## Updating the local git repository \\n')\n",
        "    os.chdir(mounted_drive / 'BAM')\n",
        "    #!git fsck --full\n",
        "    # !git add -A\n",
        "    !git stash\n",
        "    !git pull\n",
        "    # !rm -rf {mounted_drive/'BAM'}\n",
        "\n",
        "  else:\n",
        "    print('## Pulling the git repository with files for the tutorial\\n')\n",
        "    !git clone https://github.com/achri19/BAM.git\n",
        "\n",
        "  mounted_drive = mounted_drive / 'BAM'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3yYQkp4P_8I",
        "outputId": "d889a433-fc4d-4990-8fed-e51ab65f7b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "## Installing the Python packages needed for these tutorials\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if yes_colab:\n",
        "  print('\\n## Installing the Python packages needed for these tutorials\\n')\n",
        "  try:\n",
        "    import rasterio\n",
        "  except:\n",
        "    !/bin/bash $mounted_drive/notebooks/install_packages_colab.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWTZh_b8mHoE",
        "outputId": "06ccdb30-beca-4aa7-c61d-13e3937a5993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BAM/scripts\n",
            "/content/drive/MyDrive/BAM/ancillary\n"
          ]
        }
      ],
      "source": [
        "path_ancillary = mounted_drive / 'ancillary'\n",
        "path_code = mounted_drive / 'scripts/'\n",
        "path_templates = mounted_drive /  'templates/'\n",
        "path_configs = mounted_drive / 'configs/'\n",
        "sys.path.insert(1,str(path_code))\n",
        "print(path_code)\n",
        "print(path_ancillary)\n",
        "\n",
        "path_examples = mounted_drive / 'examples'\n",
        "Path(path_examples).mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4a749118"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from string import Template\n",
        "import fnmatch\n",
        "import geopandas as gpd\n",
        "import rasterio\n",
        "from osgeo import gdal\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import rtree\n",
        "from scipy import *\n",
        "import urllib.request\n",
        "import zipfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CPPe7c_zQ1aE",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7caa78-a108-4f4f-87a4-14f28cd1a19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/BAM/scripts/orinoco_tools.py:42: UserWarning: ShapelyDeprecationWarning\n",
            "  warnings.warn('ShapelyDeprecationWarning')\n",
            "/content/drive/MyDrive/BAM/scripts/orinoco_tools.py:43: UserWarning: UserWarning\n",
            "  warnings.warn('UserWarning')\n"
          ]
        }
      ],
      "source": [
        "# try:\n",
        "#   import pyTMD\n",
        "# except:\n",
        "#   !pip install pytmd\n",
        "# try:\n",
        "#     import skimage.measure as measure\n",
        "# except:\n",
        "#     !pip install scikit-image\n",
        "\n",
        "from main_tools import (build_directory,\n",
        "                       get_extent_parameters,\n",
        "                       setup_AOI_files,\n",
        "                       make_polygons,\n",
        "                       make_channel_networks,\n",
        "                       make_model_foundation,\n",
        "                       set_boundary_conditions,\n",
        "                       make_watermask,\n",
        "                       more_opening)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzirjcG0iVR4"
      },
      "source": [
        "<font size=6> Step #3: Download to your ancillary folder <br> </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTb-wcIBOHvM"
      },
      "source": [
        "# EGM08 Geoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlFK00ZePOXm"
      },
      "outputs": [],
      "source": [
        "filename = path_ancillary / 'geoids' / 'egm08_25.gtx'\n",
        "if os.path.isfile(filename)==False:\n",
        "  url = 'https://download.osgeo.org/proj/vdatum/egm08_25/egm08_25.gtx'\n",
        "  urllib.request.urlretrieve(url, filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSuwonJjOHvM"
      },
      "source": [
        "# GEBCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUSUBk0ROHvM"
      },
      "outputs": [],
      "source": [
        "filename = path_ancillary / 'gebco' / 'gebco.zip'\n",
        "if os.path.isfile(path_ancillary / 'gebco' / 'gebco_all.vrt')==False:\n",
        "  url = 'https://www.bodc.ac.uk/data/open_download/gebco/gebco_2022_sub_ice_topo/geotiff/'\n",
        "\n",
        "  try:\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "  except: print('Trouble downloading GEBCO, go to this URL to download manually: https://www.bodc.ac.uk/data/open_download/gebco/gebco_2023_sub_ice_topo/geotiff/')\n",
        "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(path_ancillary / 'gebco' )\n",
        "\n",
        "  gebco_files = [os.path.join(dirpath,f)\n",
        "                for dirpath,dirnames, files in os.walk(path_ancillary / 'gebco')\n",
        "                for f in fnmatch.filter(files,'*gebco_2022*.tif')]\n",
        "  print(gebco_files)\n",
        "\n",
        "  with open(path_ancillary / 'gebco' / 'gebco_files.txt', 'w') as f:\n",
        "    for item in gebco_files:\n",
        "      f.write(\"%s\\n\" % item)\n",
        "  ! gdalbuildvrt -input_file_list {path_ancillary}/gebco/gebco_files.txt {path_ancillary}/gebco/gebco_all.vrt\n",
        "try: os.remove(filename)\n",
        "except:''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OgYXjaGOHvM"
      },
      "source": [
        "# Global Mangrove Watch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO1psoUxOHvM"
      },
      "outputs": [],
      "source": [
        "filename = path_ancillary / 'gmw' / 'gmw_v3_2016_vec.zip'\n",
        "if os.path.isfile(filename)==False:\n",
        "  url = 'https://zenodo.org/record/6894273/files/gmw_v3_2016_vec.zip?download=1'\n",
        "  urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(path_ancillary / 'gmw')\n",
        "\n",
        "try:os.remove(filename)\n",
        "except:''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks66_4MWOHvM"
      },
      "source": [
        "# Hydropolys Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owkm-YPhOHvM"
      },
      "outputs": [],
      "source": [
        "filename = path_ancillary / 'hydropolys' / 'hydropolys.zip'\n",
        "if os.path.isfile(filename)==False:\n",
        "  url = 'http://faculty.baruch.cuny.edu/geoportal/data/esri/world/hydropolys.zip'\n",
        "  urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(path_ancillary / 'hydropolys')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1EYVAd4OHvN"
      },
      "source": [
        "# HydroLAKES Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phvGUlo2OHvN"
      },
      "outputs": [],
      "source": [
        "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:125.0) Gecko/20100101 Firefox/125.0'}\n",
        "filename = path_ancillary / 'HydroLAKES_polys_v10_shp.shp'\n",
        "if os.path.isfile(filename)==False:\n",
        "    url = 'https://data.hydrosheds.org/file/hydrolakes/HydroLAKES_polys_v10_shp.zip'\n",
        "    result = requests.get(url, headers=headers)\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(result.content)\n",
        "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "      zip_ref.extractall(path_ancillary / 'hydrolakes')\n",
        "    try:os.remove(filename)\n",
        "    except:''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK4IMDI8OHvN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ecosystems_atbd",
      "language": "python",
      "name": "ecosystems_atbd"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}